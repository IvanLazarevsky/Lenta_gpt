{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from utils.tokenization import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# import vocab\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "from utils import general_training\n",
    "import datetime\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.checkpointing import Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bpemb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_max_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_ru = bpemb.BPEmb(lang='ru', vs=vocab_max_size, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_df = pd.read_csv('lenta_gpt_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://lenta.ru/news/2006/05/09/detective/</td>\n",
       "      <td>Неизвестный расстрелял полицейский участок в о...</td>\n",
       "      <td>В понедельник неизвестный мужчина ворвался в з...</td>\n",
       "      <td>Мир</td>\n",
       "      <td>Все</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://lenta.ru/news/2005/08/18/hearing/</td>\n",
       "      <td>Адвокат спас Майкла Джексона от ареста</td>\n",
       "      <td>Адвокат Майкла Джексона приехал на заседание с...</td>\n",
       "      <td>Культура</td>\n",
       "      <td>Все</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://lenta.ru/news/2005/12/02/elections/</td>\n",
       "      <td>Ющенко пообещал не пронести \"ни копейки мимо з...</td>\n",
       "      <td>Президент Украины Виктор Ющенко призвал всех у...</td>\n",
       "      <td>Бывший СССР</td>\n",
       "      <td>Все</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://lenta.ru/news/2002/04/24/foreigners/</td>\n",
       "      <td>МВД начинает тотальную проверку иностранцев</td>\n",
       "      <td>Российские правоохранительные органы планируют...</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Все</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            url  \\\n",
       "0   https://lenta.ru/news/2006/05/09/detective/   \n",
       "1     https://lenta.ru/news/2005/08/18/hearing/   \n",
       "2   https://lenta.ru/news/2005/12/02/elections/   \n",
       "3  https://lenta.ru/news/2002/04/24/foreigners/   \n",
       "\n",
       "                                               title  \\\n",
       "0  Неизвестный расстрелял полицейский участок в о...   \n",
       "1             Адвокат спас Майкла Джексона от ареста   \n",
       "2  Ющенко пообещал не пронести \"ни копейки мимо з...   \n",
       "3        МВД начинает тотальную проверку иностранцев   \n",
       "\n",
       "                                                text        topic tags  split  \n",
       "0  В понедельник неизвестный мужчина ворвался в з...          Мир  Все  train  \n",
       "1  Адвокат Майкла Джексона приехал на заседание с...     Культура  Все  train  \n",
       "2  Президент Украины Виктор Ющенко призвал всех у...  Бывший СССР  Все  train  \n",
       "3  Российские правоохранительные органы планируют...       Россия  Все  train  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenta_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_encoded_texts = torch.load('bpe_texts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_encoded_headlines = torch.load('bpe_headlines.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, val_split, test_split = [lenta_df.split == s for s in ('train', 'val', 'test')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw_texts, val_raw_texts = [lenta_df.text[spl].values for spl in (train_split, val_split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts = [bpe_encoded_texts[spl] for spl in (train_split, val_split)]\n",
    "train_headlines, val_headlines = [bpe_encoded_headlines[spl] for spl in (train_split, val_split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_symbols = ['<PAD>', '<UNK>' ,'<SEP>', '</S>', 'SEG_TEXT', 'SEG_SUMMARY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN, UNK_TOKEN, SEP_TOKEN, EOS_TOKEN, SEG_TEXT, SEG_TEXT_SUMMARY = special_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace1dceed02d4402a0598b1934f5a611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=180000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OOV subwords:  [('[', 2356), (']', 2355), ('@', 2197), ('”', 439), ('>', 164), ('─', 155), ('•', 145), ('<', 137), ('è', 89), ('`', 75)]\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab_from_pretrained_bpe(train_texts, special_symbols, bpe_ru, vocab_max_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48763\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_SEGMENT_TEXT, ID_SEGMENT_SUMMARY = vocab.word2id(SEG_TEXT), vocab.word2id(SEG_TEXT_SUMMARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_SEP = vocab.word2id(SEP_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_ids, val_text_ids, train_headline_ids, val_headline_ids = [transform_bpe_to_ids(texts, vocab) for texts in\n",
    "                                                                     (train_texts, val_texts, train_headlines, val_headlines)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44a5dccb1b94d12b33176c2a3be82d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48757), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = extract_pretrained_bpe_embeddings(vocab, bpe_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_example(text_ids, headline_ids, vocab, truncated_length):\n",
    "    if headline_ids is None:\n",
    "#     assert len(headline_ids) + 1 <= truncated_length\n",
    "        free_text_space = truncated_length - 1 #\n",
    "    else:\n",
    "        free_text_space = truncated_length - len(headline_ids) - 2\n",
    "        \n",
    "    text_section_length = min(free_text_space, len(text_ids))\n",
    "    example = text_ids[:text_section_length]\n",
    "    \n",
    "    example.append(vocab.word2id(SEP_TOKEN))\n",
    "    if headline_ids is not None:\n",
    "        assert len(headline_ids) + len(example) + 1 <= truncated_length\n",
    "        example.extend(headline_ids)\n",
    "        example.append(vocab.word2id(EOS_TOKEN))\n",
    "        \n",
    "    return torch.tensor(example), text_section_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tensors(examples, text_segment_lengths, padded_length=None):\n",
    "    text_segment_lengths = torch.tensor(text_segment_lengths)\n",
    "    \n",
    "    tensor_length = padded_length if padded_length else max(len(example) for example in examples)\n",
    "    \n",
    "    batch_size = len(text_segment_lengths)\n",
    "    word_ids = torch.zeros(batch_size, tensor_length, dtype=torch.long)\n",
    "    \n",
    "    for i in tqdm_notebook(range(batch_size)):\n",
    "        word_ids[i,:examples[i].size(0)] = examples[i]\n",
    "        \n",
    "    segment_ids = torch.empty(batch_size, tensor_length, dtype=torch.long)\n",
    "    segment_ids_mask = torch.arange(tensor_length).expand(batch_size, tensor_length) >= text_segment_lengths.view(-1,1)\n",
    "    segment_ids[segment_ids_mask] = ID_SEGMENT_SUMMARY\n",
    "    segment_ids[~segment_ids_mask] = ID_SEGMENT_TEXT\n",
    "    \n",
    "    position_ids = torch.arange(tensor_length, dtype=torch.long).repeat(batch_size, 1)\n",
    "    shifted_position_ids = position_ids - text_segment_lengths.view(-1,1)\n",
    "    mask = shifted_position_ids > 0\n",
    "    position_ids[mask] = shifted_position_ids[mask] - 1\n",
    "\n",
    "    return  word_ids, segment_ids, position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tensors_from_ids(text_ids, headline_ids, vocab, truncated_length):\n",
    "    text_tensors = []\n",
    "    text_segment_lengths = []\n",
    "    for i in range(len(text_ids)):\n",
    "        text = text_ids[i]\n",
    "        headline = headline_ids[i] if headline_ids else None\n",
    "        text_tensor, text_segment_length = build_training_example(text, headline, vocab, truncated_length)\n",
    "        text_tensors.append(text_tensor)\n",
    "        text_segment_lengths.append(text_segment_length)        \n",
    "    \n",
    "    token_tensor, segment_tensor, position_ids = build_tensors(text_tensors, text_segment_lengths, truncated_length)\n",
    "    return token_tensor, segment_tensor, position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_length = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b2bb2143af46598bec382613ee1cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=180000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_text_tensor, train_segment_tensor, train_positions_tensor = build_tensors_from_ids(train_text_ids, train_headline_ids, vocab, truncated_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3e6ad9af334444b374015708b82230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_text_tensor, val_segment_tensor, val_positions_tensor = build_tensors_from_ids(val_text_ids, val_headline_ids, vocab, truncated_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    8,   419,  6452,   846, 21317,     8,  1323,  6428,  5199,     8,\n",
      "         3500,  4616,   250,     8,  8049,  7515,     9,  3758,  7422,     6,\n",
      "          202,    10,   200,   763,   154,   995,  2707, 18503,  2153,     7,\n",
      "            8,   146,  1854,   137,  5723,    49,  2981,     6,    91,    12,\n",
      "         8294,  1856,   176,   324,  4734,     6,     8,    76,   244, 19152,\n",
      "         5199,     7,     8,   225,  4338,  2447,  2560,   356,     6, 32748,\n",
      "           52,   319, 11204,     6,    49,  2981,     7,   281,  6292,   219,\n",
      "            6,  2560,   494,    65,   854,     6,    67,  1344,    23,  6851,\n",
      "         6798,  2523,   141,    17,  2654,   426, 15212,     7,   129,    17,\n",
      "          470,   669,   508,  3194,    12,  6823,    66,  9397,  8963,     7,\n",
      "           26,   202,     6,   846,    49,  1591,  1793,  1457, 13135,   476,\n",
      "            6,  1457,  1882,  5892, 17733,  4309,     7,  2657,   759,   100,\n",
      "           15,   693,    12,  2313,   331,     7,    12,  3041,    92,     6,\n",
      "         5524,  3471,  3120,   199,    27,    87,   397, 17183,  1391, 16948,\n",
      "         1668,   259, 19309,   288,  1029,     7,  4071,    83,    77,    49,\n",
      "           22,  2360,   426,   253,    12,  2700,     8,  2460,    28,  3556,\n",
      "         1435,  2009,     6,   372,   437,     7,     2,  6452, 14584,   115,\n",
      "         5723,  3896,     8,  8049,  7515,     3,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "print(train_text_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166,   0,\n",
      "          1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
      "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
      "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
      "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
      "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
      "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
      "        127, 128, 129, 130, 131, 132])\n"
     ]
    }
   ],
   "source": [
    "print(train_positions_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensors_for_sampling_ids(ids, vocab, reserved_space, max_text_length, beam_width):\n",
    "    text_length = min(len(ids), max_text_length)\n",
    "    ids = ids[:text_length]\n",
    "    text_tensor, segment_tensor, positions_tensor = build_tensors_from_ids([ids] * beam_width, None, vocab, text_length + reserved_space + 2)\n",
    "    return text_tensor, segment_tensor, positions_tensor, text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensors_for_sampling(tokens, vocab , reserved_space, max_text_length, beam_width=1):\n",
    "    ids = transform_bpe_to_ids([tokens], vocab)[0]\n",
    "    return make_tensors_for_sampling_ids(ids, vocab, reserved_space, max_text_length, beam_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tensors_for_sampling_raw(text, bpe, vocab, reserved_space, max_text_length, beam_width=1):\n",
    "    tokens = bpe.encode(text)\n",
    "    return make_tensors_for_sampling(tokens, vocab, reserved_space, max_text_length, beam_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c09a5a94d74f92ac9560b0acf41d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[16358,     8,   257,    10,  1561,     2,     0,     0,     0,     0,\n",
      "             0,     0]])\n",
      "tensor([[4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5]])\n",
      "tensor([[0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5]])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(*make_tensors_for_sampling_raw('Погода в Москве на сегодня, точный прогноз погоды на сегодня для населенного пункта Москва,', \n",
    "                                     bpe_ru, vocab, 5, 5, 1), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаём сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2SummaryHead(nn.Module):\n",
    "    def __init__(self, gpt_config, ignore_positions=False):\n",
    "        super().__init__()\n",
    "        self.gpt = pytorch_transformers.GPT2Model(gpt_config)\n",
    "        self.ignore_positions = ignore_positions\n",
    "        \n",
    "    def encode(self, input_ids, segment_ids, position_ids):\n",
    "        if self.ignore_positions:\n",
    "            position_ids = None\n",
    "        hidden_states = self.gpt(input_ids, position_ids=position_ids, token_type_ids=segment_ids, head_mask=None)[0]\n",
    "        return hidden_states\n",
    "    \n",
    "    def compute_logits(self, decoder_states):\n",
    "        return torch.matmul(decoder_states, self.gpt.wte.weight.t())\n",
    "        \n",
    "    def forward(self, input_ids, segment_ids, position_ids):\n",
    "        return self.compute_logits(self.encode(input_ids, segment_ids, position_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gpt(net, model_inputs, starting_index, vocab, n_times, top_k=None, device='cuda'):\n",
    "    tensor_inputs, tensor_segments, tensor_positions = [t.to(device) for t in model_inputs]\n",
    "\n",
    "    net.eval()\n",
    "#     encoder_states = net.encoder(tensor_inputs, tensor_lengths)\n",
    "    \n",
    "    beam_width = tensor_inputs.size(0)\n",
    "    results = [[] for _ in range(beam_width)]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for pos in range(starting_index, starting_index + n_times):\n",
    "            hidden_states = net.encode(tensor_inputs, tensor_segments, tensor_positions)\n",
    "            \n",
    "            # B N V\n",
    "            logits = net.compute_logits(hidden_states[:,pos:pos+1,:]).squeeze(1)\n",
    "                        \n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            if top_k:\n",
    "                probs, sampling_set = torch.topk(probs,top_k, dim=-1, sorted=False)\n",
    "                \n",
    "            cat = torch.distributions.Categorical(probs)\n",
    "            if top_k:\n",
    "                sampled = sampling_set[torch.arange(beam_width),cat.sample()]\n",
    "            else:\n",
    "                sampled = cat.sample()\n",
    "                \n",
    "            tensor_inputs[:,pos+1] = sampled\n",
    "            \n",
    "            for i, word_id in enumerate(tensor_inputs[:,pos+1].tolist()):\n",
    "                results[i].append(vocab.id2word(word_id))\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_raw(net, text, bpe, vocab, n_times, max_text_length, beam_width=1, top_k=None, device='cuda'):\n",
    "    tokens = encode_text(bpe, text, None, None)\n",
    "    sample_tensor, sample_segments, sample_positions, starting_index = make_tensors_for_sampling(tokens,\n",
    "                                                                                                 vocab, \n",
    "                                                                                                 reserved_space=n_times,\n",
    "                                                                                                 max_text_length=max_text_length,\n",
    "                                                                                                 beam_width=beam_width)\n",
    "    \n",
    "    return sample_gpt(net,(sample_tensor, sample_segments, sample_positions),\n",
    "                      starting_index, vocab, n_times, top_k, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tokens(net, tokens, vocab, n_times, max_text_length, top_k=None, device='cuda'):\n",
    "    sample_tensor, sample_segments, sample_positions, starting_index = make_tensors_for_sampling(tokens,\n",
    "                                                                                                 vocab, \n",
    "                                                                                                 reserved_space=n_times,\n",
    "                                                                                                 max_text_length=max_text_length,\n",
    "                                                                                                 beam_width=beam_width)\n",
    "    \n",
    "    return sample_gpt(net,(sample_tensor, sample_segments, sample_positions),\n",
    "                      starting_index, vocab, n_times, top_k, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_tokens(net, tokens, vocab, n_times, max_text_length, beam_width,device='cuda',score='none'):\n",
    "    sample_tensor, sample_segments, sample_positions, starting_index = make_tensors_for_sampling(tokens,\n",
    "                                                                                                 vocab, \n",
    "                                                                                                 reserved_space=n_times,\n",
    "                                                                                                 max_text_length=max_text_length,\n",
    "                                                                                                 beam_width=beam_width)\n",
    "    return beam_search_gpt(net, (sample_tensor, sample_segments, sample_positions), starting_index, vocab, n_times, device, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_raw(net,  text, bpe, vocab, n_times, max_text_length, beam_width,device='cuda',score='none'):\n",
    "    tokens = encode_text(bpe, text, None, None)\n",
    "    return beam_search_tokens(net, tokens, vocab, n_times, max_text_length, beam_width, device, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_gpt(net, model_inputs, starting_index, vocab, n_times, device='cuda', score='none'):\n",
    "    tensor_inputs, tensor_segments, tensor_positions = [t.to(device) for t in model_inputs]\n",
    "\n",
    "    net.eval()\n",
    "#     encoder_states = net.encoder(tensor_inputs, tensor_lengths)\n",
    "    \n",
    "    beam_width = tensor_inputs.size(0)\n",
    "    results = [[] for _ in range(beam_width)]\n",
    "    log_likelihoods = torch.zeros(beam_width, dtype=torch.float32, device=device)\n",
    "    \n",
    "    scores = torch.zeros(beam_width, dtype=torch.float32, device=device)\n",
    "    stopped = torch.zeros(beam_width, dtype=torch.int8, device=device)\n",
    "    eos_index = vocab.word2id(EOS_TOKEN)\n",
    "    with torch.no_grad():\n",
    "        for pos in range(starting_index, starting_index + n_times):\n",
    "            if pos == starting_index:\n",
    "                hidden_states = net.encode(tensor_inputs[0:1], tensor_segments[0:1], tensor_positions[0:1])\n",
    "                logits = net.compute_logits(hidden_states[:,pos:pos+1,:]).view(-1)\n",
    "                log_likelihoods, indices = torch.topk(F.log_softmax(logits, dim=0), beam_width)\n",
    "                tensor_inputs[:,pos+1] = indices\n",
    "                stopped[indices == eos_index] = 1\n",
    "            else:\n",
    "                hidden_states = net.encode(tensor_inputs, tensor_segments, tensor_positions)\n",
    "\n",
    "                # B N V\n",
    "                logits = net.compute_logits(hidden_states[:,pos:pos+1,:]).squeeze(1)\n",
    "                # B V\n",
    "                log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "                new_log_likelihoods = log_likelihoods.view(-1,1) + log_probs\n",
    "                \n",
    "                if score == 'divide':\n",
    "                    new_scores = new_log_likelihoods / (pos - starting_index+1)\n",
    "                else:\n",
    "                    new_scores = new_log_likelihoods\n",
    "                    \n",
    "                new_scores[stopped==1] = -1e9 \n",
    "                new_scores[stopped==1, eos_index] = scores[stopped==1]\n",
    "                new_log_likelihoods[stopped==1] = -1e9\n",
    "                new_log_likelihoods[stopped==1, eos_index] = log_likelihoods[stopped==1]\n",
    "                \n",
    "                top_scores, top_indices = torch.topk(new_scores.view(-1), beam_width)\n",
    "                \n",
    "                ancestor_idx, successor_word_idx = np.unravel_index(top_indices.tolist(), shape=tuple(logits.size()))\n",
    "\n",
    "                new_tensor_inputs = torch.empty(*tensor_inputs.size(), device=device, dtype=tensor_inputs.dtype)\n",
    "                new_stopped = torch.zeros(beam_width, dtype=torch.int8, device=device)\n",
    "                \n",
    "                for i, (ancestor, successor) in enumerate(zip(ancestor_idx, successor_word_idx)):\n",
    "#                     print(ancestor, successor)\n",
    "                    new_tensor_inputs[i] = tensor_inputs[ancestor]\n",
    "                    new_tensor_inputs[i,pos+1] = int(successor)\n",
    "                    if stopped[ancestor].item() or int(successor) == eos_index:\n",
    "                        new_stopped[i] = 1\n",
    "                        new_tensor_inputs[i,pos+1] = eos_index\n",
    "\n",
    "                tensor_inputs = new_tensor_inputs\n",
    "                stopped = new_stopped\n",
    "                log_likelihoods = new_log_likelihoods.view(-1)[top_indices]\n",
    "                scores = top_scores\n",
    "            \n",
    "\n",
    "    for pos in range(starting_index, starting_index + n_times):\n",
    "        for i, word_id in enumerate(tensor_inputs[:,pos+1].tolist()):\n",
    "            results[i].append(vocab.id2word(word_id))\n",
    "                \n",
    "    return results, scores.tolist(), log_likelihoods.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_samples(samples):\n",
    "    for s in samples:\n",
    "        print('|'.join(s))\n",
    "        print('---------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_config = pytorch_transformers.GPT2Config(vocab_size_or_config_json_file=len(vocab),\n",
    "                                                 n_special=len(special_symbols),\n",
    "                                                 n_positions=350,\n",
    "                                                  n_ctx=400,\n",
    "                                                  n_embd=300, \n",
    "                                                  n_layer=5,\n",
    "                                                  n_head=4,\n",
    "                                                  embd_pdrop=0.3\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model =  GPT2SummaryHead(decoder_config)\n",
    "decoder_model.gpt.wte.weight.data[vocab.n_specials:].copy_(torch.from_numpy(pretrained_embeddings[vocab.n_specials:]))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text1 = 'Погода в Москве на сегодня, точный прогноз погоды на сегодня для населенного пункта Москва'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f06e53ba194181b5a9995fe41c892e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"\n",
      "---------------------\n",
      "%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"\n",
      "---------------------\n",
      "▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms|▁sms\n",
      "---------------------\n",
      "▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный\n",
      "---------------------\n",
      "%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "print_samples(sample_raw(decoder_model, sample_text1, bpe_ru, vocab, 20, 100, beam_width=5, top_k=10, device='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6271ff58f2904e0db24d8e98ab49af80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"|%\"\n",
      "---------------------\n",
      "▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный|▁истребительный\n",
      "---------------------\n",
      "вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ|вказ\n",
      "---------------------\n",
      "▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width|▁width\n",
      "---------------------\n",
      "округ|округ|округ|округ|округ|округ|округ|округ|округ|округ|округ|округ|округ|округ|округ|округ|округ|округ|округ|округ\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "print_samples(beam_search_raw(decoder_model, sample_text1, bpe_ru, vocab, 20, 100, beam_width=5, device='cpu')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_cross_entropy(logits, targets, mask):\n",
    "    losses = F.cross_entropy(logits, targets, reduction='none')\n",
    "    return losses[mask.view(-1)].sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lm_loss(context, batch_state):\n",
    "    input_ids, input_segments, input_positions = (x.to(context.device) for x in batch_state.batch)\n",
    "    decoder_input_ids = input_ids[:, :-1]\n",
    "    decoder_input_segments = input_segments[:, :-1]\n",
    "    decoder_input_positions = input_positions[:, :-1]\n",
    "    target = input_ids[:, 1:]\n",
    "    logits = context.model(decoder_input_ids, decoder_input_segments, decoder_input_positions)\n",
    "    loss_mask = (target != 0) & (target != ID_SEP)\n",
    "    \n",
    "    return masked_cross_entropy(logits.view(-1, logits.size(-1)), target.contiguous().view(-1), loss_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_summary_loss(context, batch_state):\n",
    "    input_ids, input_segments, input_positions = (x.to(context.device) for x in batch_state.batch)\n",
    "    decoder_input_ids = input_ids[:, :-1]\n",
    "    decoder_input_segments = input_segments[:, :-1]\n",
    "    decoder_input_positions = input_positions[:, :-1]\n",
    "    target = input_ids[:, 1:]\n",
    "    logits = context.model(decoder_input_ids, decoder_input_segments, decoder_input_positions)\n",
    "    \n",
    "    loss_mask = (target != 0) & (decoder_input_segments == ID_SEGMENT_SUMMARY)\n",
    "    \n",
    "    return masked_cross_entropy(logits.view(-1, logits.size(-1)), target.contiguous().view(-1), loss_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "del decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_config = pytorch_transformers.GPT2Config(vocab_size_or_config_json_file=len(vocab),\n",
    "                                                 n_special=len(special_symbols),\n",
    "                                                 n_positions=350,\n",
    "                                                  n_ctx=400,\n",
    "                                                  n_embd=300, \n",
    "                                                  n_layer=5,\n",
    "                                                  n_head=4,\n",
    "                                                  embd_pdrop=0.3\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model =  GPT2SummaryHead(decoder_config)\n",
    "gpt_model.gpt.wte.weight.data[vocab.n_specials:].copy_(torch.from_numpy(pretrained_embeddings[vocab.n_specials:]))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 6e-4\n",
    "max_grad_norm = 10.0\n",
    "num_total_steps = 113000\n",
    "num_warmup_steps = 5000\n",
    "train_batch_size = 16\n",
    "gradient_accumulation_steps = 2\n",
    "n_epoch=20\n",
    "\n",
    "optimizer = pytorch_transformers.AdamW(gpt_model.parameters(), lr=lr, correct_bias=False)\n",
    "scheduler = pytorch_transformers.WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = gpt_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_timestamp():\n",
    "    return datetime.datetime.now().strftime('%Y-%m-%d_%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_after_epoch(model, idx=None):\n",
    "    idx = idx if idx is not None else np.random.randint(0, len(val_raw_texts)) # 9217\n",
    "    print(idx, val_raw_texts[idx])\n",
    "\n",
    "    tokens = val_texts[idx]\n",
    "    sample_tensor, sample_segments, sample_positions, starting_index = make_tensors_for_sampling(tokens, vocab, reserved_space=20, max_text_length=220,beam_width=5)\n",
    "\n",
    "    sr = sample_gpt(model, (sample_tensor, sample_segments, sample_positions), starting_index, vocab, 20, top_k=15, device='cuda')\n",
    "    print('\\nRandom samples: ')\n",
    "    print_samples(sr)\n",
    "    print('\\n\\nBeam search samples:')\n",
    "    \n",
    "    sr, scores, lls = beam_search_gpt(model, (sample_tensor, sample_segments, sample_positions), starting_index, vocab, 20, device='cuda',score='divide')\n",
    "    \n",
    "    print_samples(sr)\n",
    "    print(scores)\n",
    "    print(lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11499 В Луизиане буксирующее судно врезалось в основание заброшенной нефтеплатформы, спровоцировав утечку нефти, передает 27 июля Associated Press. Инцидент произошел в акватории озера Мад (Mud Lake), расположенного в заливе Баратария, который в свою очередь входит в состав обширного Мексиканского залива. По сообщениям береговых служб, буксир при транспортировке другого судна задел устьевое оборудование скважины, в результате чего оттуда начала разливаться нефть. Объемы разливающейся нефти пока не установлены. Отмечается, что струя нефти и газа, бьющая из поврежденной скважины, достигает 30 метров в высоту. На поверхности озера уже сформировалась нефтяная пленка протяженностью в два километра. Как подчеркивают представители экстренных служб, в месте ЧП уже работают суда-нефтесборщики. Ожидается, что поврежденная нефтескважина будет закрыта в ближайшее время. По заявлениям пресс-службы губернатора Бобби Джиндала (Bobby Jindal), скважина, о которой идет речь, принадлежала хьюстонской компании Cedyco, но в ноябре 2008 года была законсервирована, и с тех пор не эксплуатировалась, добавляет CNN. Примечательно, что ЧП на заброшенной скважине произошло неподалеку от того района Мексиканского залива, где в апреле 2010 года взорвалась и обрушилась нефтеплатформа BP, что привело к масштабной экологической катастрофе, ликвидировать последствия которой не удается до сих пор.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a4706b512545229378137ff83a655a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random samples: \n",
      "▁в|▁луизи|ане|▁букси|р|▁столк|нулась|▁с|▁нефтя|ной|▁уте|чкой|</S>|▁нефть|</S>|▁нефть|</S>|</S>|▁нефть|</S>\n",
      "---------------------\n",
      "▁в|▁зато|ну|вшем|▁в|▁луизи|ане|▁букси|ру|▁вреза|лось|▁в|▁стену|▁нефте|плат|формы|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁луизи|ане|▁зато|нуло|▁судно|</S>|▁нефть|</S>|▁нефть|</S>|</S>|</S>|▁катастрофа|</S>|▁нефть|</S>|▁нефть|</S>|▁нефть\n",
      "---------------------\n",
      "▁во|▁второй|▁раз|▁за|стря|вший|▁в|▁пото|плении|▁нефть|▁танк|▁вреза|лась|▁в|▁залив|</S>|00|▁метров|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁луизи|ане|▁букси|р|▁вреза|лся|▁в|▁пристань|</S>|0|</S>|0|</S>|</S>|</S>|▁прекращены|</S>|</S>|</S>\n",
      "---------------------\n",
      "\n",
      "\n",
      "Beam search samples:\n",
      "▁в|▁луизи|ане|▁букси|р|▁врезался|▁в|▁здание|▁нефте|плат|формы|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁луизи|ане|▁букси|ра|▁вреза|лась|▁в|▁здание|▁нефте|плат|формы|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁луизи|ане|▁букси|р|▁врезался|▁в|▁воду|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁луизи|ане|▁букси|ра|▁вреза|лась|▁в|▁воду|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁луизи|ане|▁букси|р|▁вреза|лся|▁в|▁воду|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "[-0.479716956615448, -0.543353259563446, -0.6489828824996948, -0.7053061723709106, -0.7188858389854431]\n",
      "[-5.756603240966797, -7.063591957092285, -5.840846061706543, -7.053061485290527, -7.1888580322265625]\n"
     ]
    }
   ],
   "source": [
    "sample_after_epoch(gpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = Checkpoint('gpt_checkpoints/chk{}_epoch{}_loss{:.3f}')\n",
    "checkpoint.loss = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint.best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def after_epoch(context, epoch_state):\n",
    "    loss = epoch_state.val_loss\n",
    "    sample_after_epoch(context.model)\n",
    "    if loss < checkpoint.loss:\n",
    "        print(\"Saving checkpoint\")\n",
    "        checkpoint.update({'config': gpt_config, \n",
    "                           'model': gpt_model.state_dict(), \n",
    "                           'optimizer': optimizer.state_dict(), \n",
    "                           'scheduler': scheduler.state_dict()},\n",
    "                          index=(current_timestamp(), epoch_state.epoch+1,loss), best=True)\n",
    "        checkpoint.loss = loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9168 Американская компания Ad Astra провела первые испытания плазменного двигателя на сверхпроводящих магнитах VX-200. Об этом сообщается в пресс-релизе компании. Следующие испытания двигателя запланированы на 14 июля 2009 года. Предыдущие испытания, которые проводились осенью 2008 года, позволили доказать работоспособность двигателя. Тогда в нем был установлен обычный магнит. Использование сверхпроводящего аналога позволило увеличить мощность VX-200 примерно в 10 раз. Видео испытания доступно здесь. Испытанный двигатель относится к системе VASIMR (Variable Specific Impulse Magnetoplasma Rocket) - магнитоплазменных ракетных двигателей с переменным импульсом. Ранее подобные двигатели разрабатывались NASA, однако в настоящее время исследования полностью ведет компания Ad Astra, расположенная в Коста-Рике. Принцип работы двигателя заключается в следующем: в специальной камере под воздействием электромагнитных волн материя (обычно благородный газ) ионизируется. Под воздействием магнитного поля она направляется в сопло, вылетая из которого, создает тягу. В обычном двигателе вместо плазмы из сопла вылетают раскаленные газы, образовавшиеся после сжигания топлива. Теоретически, новые двигатели не дают мощную тягу, однако способны работать достаточно долго, сообщая в результате аппарату в космическом пространстве большую скорость, чем привычные ракетные двигатели. В настоящее время инженеры решают ряд проблем, связанных с высоким тепловыделением данного устройства. В будущем (в случае успеха испытаний) подобный двигатель планируется протестировать на МКС.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62eff604d2d743db9cce7d478371aa43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Random samples: \n",
      "▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной|▁архитектурной\n",
      "---------------------\n",
      "▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза\n",
      "---------------------\n",
      "▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной\n",
      "---------------------\n",
      "▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной\n",
      "---------------------\n",
      "▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной\n",
      "---------------------\n",
      "\n",
      "\n",
      "Beam search samples:\n",
      "▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной|▁виртуальной\n",
      "---------------------\n",
      "▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза|▁бронза\n",
      "---------------------\n",
      "сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт|сорт\n",
      "---------------------\n",
      "▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону|▁биатлону\n",
      "---------------------\n",
      "смер|смер|смер|смер|смер|смер|смер|смер|смер|смер|смер|смер|смер|смер|смер|смер|смер|смер|смер|смер\n",
      "---------------------\n",
      "[-0.047200966626405716, -0.10000591725111008, -0.12441311031579971, -0.14758720993995667, -0.15332460403442383]\n",
      "[-0.9440193176269531, -2.0001182556152344, -2.488262176513672, -2.9517440795898438, -3.0664920806884766]\n",
      "Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "after_epoch(general_training.AttrDict({'model': gpt_model}),general_training.AttrDict({'epoch': 4, 'val_loss': 4.145}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_step(context, batch_state):\n",
    "#     current_lr = next(iter(context.optimizer.param_groups))['lr']\n",
    "#     writer.add_scalar('Learning rate', current_lr, batch_state.total_steps)\n",
    "#     writer.add_scalar('Training loss', batch_state.loss, batch_state.total_steps)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_grad(context, batch_state):\n",
    "    torch.nn.utils.clip_grad_norm_(context.model.parameters(), max_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_text_tensor, train_segment_tensor, train_positions_tensor)\n",
    "val_dataset = TensorDataset(val_text_tensor, val_segment_tensor, val_positions_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TensorDataset(train_text_tensor[:100], train_segment_tensor[:100], train_positions_tensor[:100])\n",
    "# val_dataset = TensorDataset(val_text_tensor[:100], val_segment_tensor[:100], val_positions_tensor[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_training.train_general(gpt_model, optimizer,\n",
    "                              compute_lm_loss, compute_summary_loss,\n",
    "                              train_loader, val_loader, \n",
    "                              n_epoch, gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                              n_prints=4, after_epoch=after_epoch, after_gradient=clip_grad, after_step=after_step)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "persisted = torch.load('gpt_checkpoints/chk2019-08-26_065533_epoch16_loss2.221')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['config', 'model', 'optimizer', 'scheduler'])\n"
     ]
    }
   ],
   "source": [
    "print(persisted.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_model.load_state_dict(persisted['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(persisted['optimizer'])\n",
    "scheduler.load_state_dict(persisted['scheduler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 26 07:15:06 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 25%   46C    P2    57W / 250W |   1701MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.general_training' from '/home/lenta/utils/general_training.py'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(general_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8b7e52986e4b679848f40e2199008d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e880613ecc28422f86536dfb1ddfa66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Iteration 2812 Loss 1.6573249956706848\n",
      "Epoch 17 Iteration 5624 Loss 1.658568224603387\n",
      "Epoch 17 Iteration 8436 Loss 1.6585102523034532\n",
      "Epoch 17 Iteration 11248 Loss 1.6589942226559984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e145c6608a3c466cba84cdf0e70a11f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 val_Loss 2.2140766849517823\n",
      "11235 Свидетель нападения на актера Александра Ляпина, известного по сериалу «Интерны», рассказал о произошедшем в одном из московских кафе. Как он уточнил телеканалу НТВ, артист находился в состоянии алкогольного опьянения. По словам свидетеля, охранникам заведения не понравилось, что артист был пьян, они вывели его на улицу и «потолкались». «Вроде побоев, драки не было, просто потолкались, и потом подъехала полиция», — рассказал он. По информации Life, в потасовке участвовали посетители, которые также были в нетрезвом состоянии. Портал отмечает, что тяжелых травм, о которых сообщалось ранее, актер не получал. Участники конфликта были задержаны. По факту произошедшего инициирована проверка. Инцидент произошел в ночь на 27 июня возле ночного клуба на Грузинском Валу. Как сообщалось, на молодого человека и его подругу Полину Левашкевич напали семь человек. В результате актер получил сотрясение мозга и травму носа. 30-летний Ляпин снимается в кино и сериалах с 2007 года.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b607138c624a95a56ff86fdf54a0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random samples: \n",
      "▁в|▁московском|▁ресторане|▁устроил|▁нападение|▁на|▁актера|▁на|▁актера|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁сми|▁рассказа|ли|▁о|▁нападении|▁на|▁актера|▁алексея|▁ля|пина|</S>|х|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁напа|вший|▁на|▁актера|▁ля|пина|▁из|▁ресторана|▁на|▁улице|▁ля|пина|▁рассказал|▁о|▁произошед|шем|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁москве|▁у|▁пья|ных|▁посетителей|▁напа|вшего|▁на|▁актера|▁напали|▁в|▁кафе|▁с|▁алкого|льными|▁оп|ья|нения|ми\n",
      "---------------------\n",
      "▁ск|▁рассказал|▁о|▁поку|шении|▁на|▁актера|▁в|▁ресторане|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "\n",
      "\n",
      "Beam search samples:\n",
      "▁свидетель|▁нападения|▁на|▁актера|▁ля|пина|▁рассказал|▁о|▁произошед|шем|▁в|▁кафе|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁свидетель|▁нападения|▁на|▁актера|▁ля|пина|▁рассказал|▁о|▁произошед|шем|▁в|▁кафе|▁«|интер|ны|»|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁свидетель|▁нападения|▁на|▁актера|▁ля|пина|▁рассказал|▁о|▁случи|вшемся|▁в|▁кафе|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁свидетель|▁нападения|▁на|▁актера|▁ля|пина|▁рассказал|▁о|▁произошед|шем|▁в|▁кафе|▁в|▁москве|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁свидетель|▁нападения|▁на|▁актера|▁ля|пина|▁рассказал|▁о|▁произошед|шем|▁в|▁ресторане|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "[-0.5799902081489563, -0.5941104888916016, -0.660320520401001, -0.6739648580551147, -0.6794216632843018]\n",
      "[-7.539872169494629, -10.099878311157227, -8.584166526794434, -10.109472274780273, -8.832481384277344]\n",
      "Saving checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1729f1945238404cbcd63d78b44b6515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Iteration 2812 Loss 1.6522933844143093\n",
      "Epoch 18 Iteration 5624 Loss 1.6526100246784188\n",
      "Epoch 18 Iteration 8436 Loss 1.6528366976238755\n",
      "Epoch 18 Iteration 11248 Loss 1.652500656143276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efece6709f6544f1be45726dd205496d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 val_Loss 2.206396284421285\n",
      "11042 К обвиняемой в смерти блокадницы после конфликта в петербургском магазине «Магнит» применили амнистию. Об этом сообщает ТАСС из зала Кронштадтского районного суда. «Суд считает необходимым удовлетворить ходатайство [бывшего директора магазина Ольги] Конюховой об амнистии в соответствии с постановлением Госдумы об амнистии к 70-летию Победы за преступления, предусматривающие наказание до 5 лет лишения свободы», — заявила судья. Она отметила, что Конюхова обвиняется в преступлениях небольшой тяжести, а обстоятельств, препятствующих применению амнистии, не установлено. В связи с этим суд прекращает уголовное дело. Ходатайство было заявлено в четверг, 18 июня. Адвокат, представляющий интересы родственников 81-летней блокадницы Раузы Галимовой, отметил, что основания для применения акта амнистии есть. Племянница Галимовой Дина Соколова просила суд провести разбирательство. «Я хочу, чтобы она была наказана, а потом получила амнистию», — отметила она. На заседании 1 июня родственники блокадницы подали иск о компенсации морального вреда на миллион рублей. Эти средства потерпевшая сторона требовала взыскать с обвиняемой, а также с компании «Тандер», которая владеет продовольственной сетью «Магнит». В феврале Конюховой предъявили обвинение в самоуправстве (статья 330 УК РФ) и причинении смерти по неосторожности (статья 109). По версии следствия, 3 февраля в магазине «Магнит» директор, увидев, что пожилая покупательница не заплатила за три пачки масла (хотя заплатила за все остальные продукты), спровоцировала конфликтную ситуацию. Конюхова отказалась взять предложенные блокадницей деньги. Товар у женщины изъяли, хотя не имели на то полномочий, и вызвали полицию. Галимову доставили в отдел, где она умерла от инфаркта «в результате действий обвиняемой». Расследование дела было завершено в апреле. Среди фигурантов других резонансных дел, к которым применили амнистию, — дочь члена иркутского избиркома Анна Шавенкова, сбившая в 2009 году двух девушек, одна из которых скончалась, а вторая осталась инвалидом. Был также амнистирован саровский физик Владимир Голубев, обвиненный летом 2014-го в разглашении государственной тайны. По состоянию на 5 июня под амнистию к 70-летию Победы в Великой Отечественной войне попали более 67 тысяч человек. Амнистия вступила в силу 24 апреля и продлится полгода.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8879dd0e7d5945999353055f2a6505c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random samples: \n",
      "▁суд|▁отказался|▁об|жало|вать|▁дело|▁о|▁беспоряд|ках|▁на|▁«|магни|т|нике|»|</S>|▁суд|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁суд|▁обяза|л|▁осужден|ного|▁выплатить|▁инвали|дность|▁за|▁попытку|▁побега|▁в|▁петербурге|</S>|</S>|</S>|гия|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁мать|▁«|магни|т|ника|»|▁подала|▁апел|ляцию|▁на|▁амнисти|ю|▁за|▁убийство|▁коллеги|</S>|хи|</S>|ей|</S>\n",
      "---------------------\n",
      "▁суд|▁запретил|▁осу|жденным|▁в|▁колонии|▁бывшего|▁зам|пре|да|▁мо|соб|ла|суд|</S>|о|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁суд|▁решил|▁освободить|▁осужден|ную|▁в|▁«|магни|т|нике|»|▁00-|летнюю|▁стару|шку|</S>|ню|</S>|</S>|</S>\n",
      "---------------------\n",
      "\n",
      "\n",
      "Beam search samples:\n",
      "▁в|▁петербургском|▁магазине|▁«|магни|т|»|▁примени|ли|▁амнисти|ю|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁петербургском|▁магазине|▁«|магни|т|»|▁примени|ли|▁амнисти|ю|▁для|▁осу|жденных|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁петербургском|▁магазине|▁«|магни|та|»|▁примени|ли|▁амнисти|ю|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁петербургском|▁магазине|▁«|магни|т|»|▁примени|ли|▁амнисти|ю|▁из|-|за|▁амнистии|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁петербургском|▁магазине|▁«|магни|т|»|▁примени|ли|▁амнисти|ю|▁для|▁обвиня|емой|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "[-0.5586795210838318, -0.6544798016548157, -0.6881777048110962, -0.6913281679153442, -0.7161558270454407]\n",
      "[-6.704154014587402, -9.8171968460083, -8.258131980895996, -11.061250686645508, -10.742337226867676]\n",
      "Saving checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fb79f637a244529114fbb5835f1454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Iteration 2812 Loss 1.6466469207664642\n",
      "Epoch 19 Iteration 5624 Loss 1.646415644019291\n",
      "Epoch 19 Iteration 8436 Loss 1.6468234356402673\n",
      "Epoch 19 Iteration 11248 Loss 1.646873932909406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76135b5e55146eea24906b0fd462c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 val_Loss 2.2012045011520387\n",
      "8059 Шесть израильских солдат были ранены в перестрелках с партизанами \"Хизбалла\", произошедших в воскресенье на севере Израиля. Первый инцидент произошел у поста Армии обороны Израиля в районе Хар-Дов (Har Dov). Двое солдат получили ранения легкой и средней степеней тяжести. В перестрелке боевики \"Хизбаллы\" применили минометы и противотанковые ракеты. Спустя некоторое время еще четыре женщины-военнослужащих были ранены в ходе минометного обстрела военного аванпоста в Мошав-Авивим (Moshav Avivim), в районе верхней Галилеи (Upper Galilee). В обоих случаях израильская сторона отвечала артиллерийским огнем. В районы столкновений также были направлены военные вертолеты. Боевики \"Хизбаллы\" мотивируют свои действия тем, что граница между Ливаном и Израилем неверна и район Хар-Дов должен принадлежать Ливану. Сам Ливан признает границу с Израилем законной. Министр обороны страны Халил аль-Храви (Khalil al-Hrawi) заявил в воскресенье: \"Позиция ливанского правительства заключается в том, чтобы не добустить любые военные действия с территории страны через границу, которую Ливан признает\". В воскресенье представители ливанских служб безопасности сообщили, что ливанские военные задержали на своей территории четырех палестинцев, подозреваемых в причастности к обстрелам израильских позиций в деревне Гайяр (Ghajar). Поздно вечером в воскресенье в телефонном разговоре с госсекретарем США Колином Пауэллом министр иностранных дел Израиля Шимон Перес попросил США вмешаться в конфликт и помочь в разрешении вопроса между Ливаном, Сирией и Израилем с тем, чтобы прекратить нападения на границе.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2df1b9bc0e744829b517f2482da6a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random samples: \n",
      "▁израиль|ские|▁солдаты|▁обстре|ляли|▁из|▁грана|то|метов|</S>|х|</S>|х|</S>|ха|</S>|</S>|ха|ви|м\n",
      "---------------------\n",
      "▁израиль|ские|▁солдаты|▁расстреляли|▁израильского|▁солдата|</S>|▁армия|</S>|льская|</S>|▁армия|</S>|▁армия|</S>|лена|</S>|хия|</S>|▁не\n",
      "---------------------\n",
      "▁израиль|ские|▁солдаты|▁ранены|▁в|▁перестре|лке|▁со|▁стороны|▁сил|▁обороны|▁израиля|</S>|▁ранены|</S>|</S>|хия|</S>|хия|</S>\n",
      "---------------------\n",
      "▁израильский|▁солдат|▁обстре|лял|▁солдат|▁в|▁секторе|▁газа|</S>|лах|</S>|▁армия|▁обороны|</S>|та|</S>|хия|</S>|</S>|хия\n",
      "---------------------\n",
      "▁четыре|▁палестин|ца|▁ранены|▁в|▁ответ|▁на|▁военные|▁действия|▁израиля|</S>|▁армия|</S>|▁армия|</S>|▁армия|</S>|</S>|хия|</S>\n",
      "---------------------\n",
      "\n",
      "\n",
      "Beam search samples:\n",
      "▁в|▁перестре|лках|▁с|▁\"|хи|з|бал|лой|\"|▁ранены|▁два|▁израильских|▁солдата|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁перестре|лках|▁с|▁\"|хи|з|бал|лой|\"|▁погибли|▁два|▁израильских|▁солдата|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁перестре|лках|▁с|▁\"|хи|з|бал|лой|\"|▁убиты|▁двое|▁израиль|тян|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁перестре|лках|▁с|▁\"|хи|з|бал|лой|\"|▁в|▁израиле|▁ранены|▁два|▁израильских|▁солдата|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁в|▁перестре|лках|▁с|▁\"|хи|з|бал|лой|\"|▁в|▁израиле|▁погибли|▁два|▁израильских|▁солдата|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "[-0.6439749002456665, -0.6542218327522278, -0.6717438101768494, -0.7837749123573303, -0.7993237972259521]\n",
      "[-9.659623146057129, -9.813326835632324, -10.076156616210938, -13.324172973632812, -13.588504791259766]\n",
      "Saving checkpoint\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e60cb3687d942d2ae9781b7b417ee77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Iteration 2812 Loss 1.6423811360578957\n",
      "Epoch 20 Iteration 5624 Loss 1.6417035261012751\n",
      "Epoch 20 Iteration 8436 Loss 1.6419111271642746\n",
      "Epoch 20 Iteration 11248 Loss 1.6419290392679475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f0832a3add4a698cfdc7bb54158e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=375), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 val_Loss 2.1952906808853148\n",
      "1251 Южная Корея нанесла высокоточные ракетные удары по учебным целям в ответ на запуск баллистической ракеты КНДР. Об этом во вторник, 28 ноября, сообщает ТАСС со ссылкой на заявление Комитета начальника штабов вооруженных сил страны. Глава комитета Госдумы по обороне Юрий Швыткин сообщил «Интерфаксу», что запуск ракеты КНДР ставит под сомнение безопасность делегации российского парламента, которая сейчас находится там с официальным визитом. «Могут последовать ответные действия со стороны Южной Кореи, со стороны Японии, США», — пояснил он. Ранее во вторник южнокорейские военные заявили о ракетном пуске с территории Северной Кореи. Отмечалось, что он был осуществлен в провинции Пхеннан-Намдо. Ракета полетела в восточном направлении.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f985cb24477406497e34d63da5ea3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random samples: \n",
      "▁южная|▁корея|▁нанесла|▁удар|▁по|▁ракетной|▁ракетной|▁цели|</S>|там|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁кндр|▁нанесла|▁ракетные|▁удары|▁по|▁объектам|▁северной|▁кореи|</S>|0|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁кндр|▁произвела|▁балли|стическую|▁атаку|▁кндр|</S>|сша|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|▁сша|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁кндр|▁пора|зила|▁ядерный|▁запуск|▁ракет|у|▁кндр|</S>|</S>|тах|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁южная|▁корея|▁произвела|▁ответный|▁запуск|▁балли|стической|▁ракеты|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "\n",
      "\n",
      "Beam search samples:\n",
      "▁кндр|▁нанесла|▁ракетные|▁удары|▁по|▁учебным|▁целям|▁в|▁ответ|▁на|▁запуск|▁кндр|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁кндр|▁нанесла|▁ракетные|▁удары|▁по|▁учебным|▁целям|▁в|▁ответ|▁на|▁запуск|▁северокорей|ской|▁ракеты|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁южная|▁корея|▁нанесла|▁ракетные|▁удары|▁по|▁учебным|▁целям|▁в|▁ответ|▁на|▁запуск|▁кндр|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁кндр|▁нанесла|▁ракетные|▁удары|▁по|▁учебным|▁целям|▁в|▁ответ|▁на|▁ракетный|▁удар|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁кндр|▁нанесла|▁ракетные|▁удары|▁по|▁учебным|▁целям|▁в|▁ответ|▁на|▁запуск|▁ракеты|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "[-0.5790916681289673, -0.5914956331253052, -0.6155146360397339, -0.6222005486488342, -0.6844281554222107]\n",
      "[-7.528191566467285, -8.87243366241455, -8.617204666137695, -8.088606834411621, -8.897565841674805]\n",
      "Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "general_training.train_general(gpt_model, optimizer,\n",
    "                              compute_lm_loss, compute_summary_loss,\n",
    "                              train_loader, val_loader, \n",
    "                              4, gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                              n_prints=4, initial_epoch=16, after_epoch=after_epoch, after_gradient=clip_grad, after_step=after_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text2 = \"\"\"Российский космонавт Александр Скворцов, выполнявший в ручном режиме перестыковку корабля \"Союз МС-13\" с одного модуля МКС на другой, использовал минимально возможное количество топлива, сообщил журналистам руководитель полета российского сегмента Международной космической станции Владимир Соловьев журналистам.\n",
    "\n",
    "Он отметил, что примерно в 07:30 по московскому времени на корабле \"Союз МС-14\" с роботом FEDOR будет проведен двухимпульсный маневр с целью выстраивания оптимальной траектории полёта при стыковке корабля с МКС, которая намечена на утро вторника.\n",
    "\n",
    "В понедельник утром экипаж \"Союза МС-13\", на борту которого находились командир корабля Александр Скворцов и два бортинженера Лука Пармитано и Эндрю Морган, отстыковался от причального модуля \"Звезда\", а затем в ручном режиме был пристыкован к МИМ2.\n",
    "\n",
    "Во вторник к модулю \"Звезда\" должен пристыковаться корабль \"Союз МС-14\" с человекоподобным роботом FEDOR. До этого, в понедельник, в 08:30 этот корабль также совершит специальный маневр, чтобы во вторник начать вторую попытку стыковки с МКС. Она намечена на 6:12 вторника.\n",
    "\n",
    "В субботу транспортный пилотируемый корабль \"Союз МС-14\" не смог пристыковаться к МКС. По предварительным данным, причиной неудачи стали проблемы с радиооборудованием, задействованном на ближнем участке приближения корабля к станции во время автоматической стыковки при помощи системы \"Курс\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text3 = \"\"\"\n",
    "Космический аппарат (КА) «Глонасс-М» № 742 российской глобальной навигационной спутниковой системы ГЛОНАСС, запущенный в октябре 2011 года, выведен 26 августа на внеплановое техническое обслуживание, о котором заранее не говорилось. Об этом сообщает РИА Новости.\n",
    "\n",
    "Агентство обратило внимание на данные информационно-аналитического центра ГЛОНАСС, согласно которым в настоящее время 22 КА используются по целевому назначению, а два КА временно выведены на техобслуживание.\n",
    "\n",
    "Ранее в августе агентство упомянуло, что более половины КА системы ГЛОНАСС работают за пределами гарантийного срока. 1 августа старейший КА ГЛОНАСС («Глонасс-М» № 717) был выведен на незапланированное техобслуживание.\n",
    "\n",
    "Для покрытия территории всей Земли ГЛОНАСС необходима активная работа 24 КА, тогда как для покрытия всей России достаточно 18 активных КА.\n",
    "\n",
    "В июне в заключении Счетной палаты по проекту поправок к федеральному бюджету на 2019 год указывалось, что санкции стран Запада, введенные в отношении электроники военного и двойного назначений, привели к сокращению финансирования ГЛОНАСС. В апреле замгендиректора «Роскосмоса» Юрий Урличич заявил, что точность ГЛОНАСС к 2025 году повысится на четверть. В том же месяце источники сообщали, что завершение эксплуатации тяжелых ракет «Протон-М» и неготовность создаваемых им на замену носителей «Ангара-А5» привели к необходимости уменьшения массы спутников ГЛОНАСС.\n",
    "\n",
    "В марте президент некоммерческого партнерства системы Александр Гурко заявил, что Индия будет производить навигационные чипсеты (составная часть навигационных систем для получения сигналов со спутников) ГЛОНАСС российской разработки. В апреле 2018-го гендиректор ИСС Николай Тестоедов рассказал, что космические аппараты ГЛОНАСС почти на 40 процентов состоят из зарубежных комплектующих.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁российский', '▁космонав', 'т', '▁александр', '▁сквор', 'цов', ',', '▁выполня', 'вший', '▁в', '▁ру', 'чном', '▁режиме', '▁пере', 'сты', 'ков', 'ку', '▁корабля', '▁\"', 'союз', '▁мс', '-00', '\"', '▁с', '▁одного', '▁модуля', '▁мкс', '▁на', '▁другой', ',', '▁использовал', '▁минима', 'льно', '▁возможное', '▁количество', '▁топлива', ',', '▁сообщил', '▁журналиста', 'м', '▁руководитель', '▁полета', '▁российского', '▁сегмента', '▁международной', '▁космической', '▁станции', '▁владимир', '▁солов', 'ьев', '▁журналиста', 'м', '.', '▁он', '▁отметил', ',', '▁что', '▁примерно', '▁в', '▁00:00', '▁по', '▁московскому', '▁времени', '▁на', '▁корабле', '▁\"', 'союз', '▁мс', '-00', '\"', '▁с', '▁робо', 'том', '▁fed', 'or', '▁будет', '▁проведен', '▁дву', 'хим', 'пуль', 'сный', '▁манев', 'р', '▁с', '▁целью', '▁вы', 'страи', 'вания', '▁оптима', 'льной', '▁траектории', '▁полёта', '▁при', '▁сты', 'ков', 'ке', '▁корабля', '▁с', '▁мкс', ',', '▁которая', '▁наме', 'чена', '▁на', '▁утро', '▁втор', 'ника', '.', '▁в', '▁понедельник', '▁утром', '▁экипаж', '▁\"', 'союза', '▁мс', '-00', '\",', '▁на', '▁борту', '▁которого', '▁находились', '▁командир', '▁корабля', '▁александр', '▁сквор', 'цов', '▁и', '▁два', '▁бор', 'тинже', 'нера', '▁лука', '▁пар', 'мита', 'но', '▁и', '▁эндрю', '▁морган', ',', '▁от', 'сты', 'кова', 'лся', '▁от', '▁прича', 'льного', '▁модуля', '▁\"', 'звезда', '\",', '▁а', '▁затем', '▁в', '▁ру', 'чном', '▁режиме', '▁был', '▁при', 'сты', 'кова', 'н', '▁к', '▁ми', 'м', '0.', '▁во', '▁втор', 'ник', '▁к', '▁моду', 'лю', '▁\"', 'звезда', '\"', '▁должен', '▁при', 'сты', 'кова', 'ться', '▁корабль', '▁\"', 'союз', '▁мс', '-00', '\"', '▁с', '▁человеко', 'подоб', 'ным', '▁робо', 'том', '▁fed', 'or', '.', '▁до', '▁этого', ',', '▁в', '▁понедельник', ',', '▁в', '▁00:00', '▁этот', '▁корабль', '▁также', '▁соверши', 'т', '▁специальный', '▁манев', 'р', ',', '▁чтобы', '▁во', '▁втор', 'ник', '▁начать', '▁вторую', '▁попытку', '▁сты', 'ковки', '▁с', '▁мкс', '.', '▁она', '▁наме', 'чена', '▁на', '▁0:00', '▁втор', 'ника', '.', '▁в', '▁субботу', '▁транспортный', '▁пилотиру', 'емый', '▁корабль', '▁\"', 'союз', '▁мс', '-00', '\"', '▁не', '▁смог', '▁при', 'сты', 'кова', 'ться', '▁к', '▁мкс', '.', '▁по', '▁предвари', 'тельным', '▁данным', ',', '▁причиной', '▁неудачи', '▁стали', '▁проблемы']\n"
     ]
    }
   ],
   "source": [
    "print(encode_text(bpe_ru,sample_text2, None, None)[:260])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6b56eff05f4e9a9d7e5787582ee13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sr, scores, lls = beam_search_raw(gpt_model, sample_text2, bpe_ru, vocab, 22, 260, 40, score='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁при|сты|кова|лся|▁к|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁космонав|т|▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁российский|▁космонав|т|▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁получил|▁минима|льную|▁массу|▁топлива|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁при|сты|кова|лся|▁к|▁мкс|▁к|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁сделал|▁оптима|льную|▁посадку|▁на|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁нашел|▁оптима|льное|▁количество|▁топлива|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁космонав|т|▁\"|союз|▁мс|-00|\"|▁получил|▁минима|льные|▁двигатели|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁за|стря|кова|лся|▁на|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁при|сты|кова|лся|▁на|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁за|стря|кова|лся|▁на|▁орбите|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁\"|союза|▁мс|-00|\"|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁при|сты|кова|лся|▁с|▁робо|том|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁нашел|▁оптима|льное|▁количество|▁топлива|▁для|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁при|сты|кова|лся|▁к|▁мкс|▁с|▁робо|том|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁00|▁до|▁00|▁тонн|▁топлива|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁\"|прогре|сса|\"|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁полета|▁на|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁\"|союз|▁мс|-00|\"|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁00|▁до|▁00|▁тонн|▁топлива|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁при|сты|кова|лся|▁к|▁мкс|▁на|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁\"|союза|▁мс|-00|\"|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁\"|прогре|сса|\"|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁мкс|▁на|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁космонав|т|▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁00|▁до|▁00|▁тонн|▁топлива|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁в|▁ру|чном|▁режиме|▁пере|сты|кова|лся|▁на|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁в|▁ру|чном|▁режиме|▁пере|сты|кова|лся|▁к|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁космонав|т|▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁полета|▁на|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁космонав|т|▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁\"|союза|▁мс|-00|\"|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁в|▁ру|чном|▁режиме|▁пере|сты|кова|лся|</S>|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁космонав|т|▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁мкс|▁на|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁космонав|т|▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁мкс|▁до|▁мкс|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁российский|▁космонав|т|▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁00|▁до|▁00|▁тонн|▁топлива|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁\"|союз|▁мс|-00|\"|▁и|▁\"|союз|▁мс|-00|\"|▁создали|▁минима|льно|▁топлива|</S>|</S>|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁в|▁ру|чном|▁режиме|▁пере|сты|кова|лся|▁с|▁робо|том|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁\"|прогре|сса|\"|▁до|▁мкс|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁\"|союз|▁мс|-00|\"|▁от|сты|кова|лся|▁от|▁\"|союза|▁мс|-00|\"|▁до|▁мкс|</S>|</S>|</S>|</S>|</S>\n",
      "---------------------\n",
      "▁экипаж|▁\"|союза|▁мс|-00|\"|▁в|▁ру|чном|▁режиме|▁пере|сты|кова|лся|▁на|▁\"|союз|\"|</S>|</S>|</S>|</S>\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "print_samples(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "экипаж \"союза мс-00\" пристыковался к мкс</S></S></S></S></S></S></S></S></S></S>\n",
      "\"союз мс-00\" отстыковался от мкс</S></S></S></S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" отстыковался от мкс</S></S></S></S></S></S></S></S></S></S>\n",
      "космонавт \"союз мс-00\" отстыковался от мкс</S></S></S></S></S></S></S></S></S>\n",
      "российский космонавт \"союз мс-00\" отстыковался от мкс</S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" получил минимальную массу топлива</S></S></S></S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" пристыковался к мкс к мкс</S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" сделал оптимальную посадку на мкс</S></S></S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" нашел оптимальное количество топлива</S></S></S></S></S></S></S></S></S></S></S>\n",
      "космонавт \"союз мс-00\" получил минимальные двигатели</S></S></S></S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" застряковался на мкс</S></S></S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" пристыковался на мкс</S></S></S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" застряковался на орбите</S></S></S></S></S></S></S></S></S></S>\n",
      "\"союз мс-00\" отстыковался от \"союза мс-00\"</S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" пристыковался с роботом</S></S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" нашел оптимальное количество топлива для мкс</S></S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" пристыковался к мкс с роботом</S></S></S></S></S></S></S>\n",
      "\"союз мс-00\" отстыковался от 00 до 00 тонн топлива</S></S></S></S></S></S></S>\n",
      "\"союз мс-00\" отстыковался от \"прогресса\"</S></S></S></S></S></S></S></S>\n",
      "\"союз мс-00\" отстыковался от полета на мкс</S></S></S></S></S></S></S></S></S>\n",
      "\"союз мс-00\" отстыковался от \"союз мс-00\"</S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" отстыковался от 00 до 00 тонн топлива</S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" пристыковался к мкс на мкс</S></S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" отстыковался от \"союза мс-00\"</S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" отстыковался от \"прогресса\"</S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" отстыковался от мкс на мкс</S></S></S></S></S></S></S></S>\n",
      "космонавт \"союз мс-00\" отстыковался от 00 до 00 тонн топлива</S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" в ручном режиме перестыковался на мкс</S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" в ручном режиме перестыковался к мкс</S></S></S></S></S></S>\n",
      "космонавт \"союз мс-00\" отстыковался от полета на мкс</S></S></S></S></S></S></S>\n",
      "космонавт \"союз мс-00\" отстыковался от \"союза мс-00\"</S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" в ручном режиме перестыковался</S></S></S></S></S></S></S></S>\n",
      "космонавт \"союз мс-00\" отстыковался от мкс на мкс</S></S></S></S></S></S></S>\n",
      "космонавт \"союз мс-00\" отстыковался от мкс до мкс</S></S></S></S></S></S></S>\n",
      "российский космонавт \"союз мс-00\" отстыковался от 00 до 00 тонн топлива</S></S></S></S>\n",
      "\"союз мс-00\" и \"союз мс-00\" создали минимально топлива</S></S></S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" в ручном режиме перестыковался с роботом</S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" отстыковался от \"прогресса\" до мкс</S></S></S></S></S>\n",
      "\"союз мс-00\" отстыковался от \"союза мс-00\" до мкс</S></S></S></S></S>\n",
      "экипаж \"союза мс-00\" в ручном режиме перестыковался на \"союз\"</S></S></S></S>\n"
     ]
    }
   ],
   "source": [
    "for s in sr:\n",
    "    print(bpe_ru.decode(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
